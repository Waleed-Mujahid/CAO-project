{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cao_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1LF6I2j6YT3jKU0CSAzvqZR6CPJdydW33",
      "authorship_tag": "ABX9TyPewukxtnkDk//fI/Rek7rb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Waleed-Mujahid/CAO-project/blob/main/Cao_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mituc69YjUw"
      },
      "outputs": [],
      "source": [
        "# including dependecies\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image dimensions, set as per need\n",
        "img_width, img_height = 48,48  # 96 x 96 are suitable for micro-controllers"
      ],
      "metadata": {
        "id": "td-Dux8PYouD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading our dataset from Drive\n",
        "# First mount drive\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/faceData/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/faceData/test'"
      ],
      "metadata": {
        "id": "z86wli32MjZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data pre-processing\n",
        "train_datagen = ImageDataGenerator( \n",
        "rescale=1. / 255,\n",
        "shear_range=0.2,\n",
        "zoom_range=0.2,\n",
        "horizontal_flip=True)"
      ],
      "metadata": {
        "id": "Y-PvRWTkbONJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "metadata": {
        "id": "ujHCX9KYb2x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting data generator from directory\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "train_data_dir,\n",
        "batch_size = 16,\n",
        "target_size=(img_width, img_height),\n",
        "class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "validation_data_dir,\n",
        "batch_size = 21,\n",
        "target_size=(img_width, img_height),\n",
        "class_mode='binary')"
      ],
      "metadata": {
        "id": "nt2U9ADidBC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating our model with Keras\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(3, (12, 12),activation='relu', input_shape=(img_width, img_height,3)))  # Input size of all images must be standard for model\n",
        "model.add(MaxPooling2D(strides=2))\n",
        "\n",
        "# model.add(Conv2D(10, (5, 5), activation='relu'))\n",
        "# model.add(MaxPooling2D(strides=2))\n",
        "\n",
        "model.add(Conv2D(6, (12, 12), activation='relu'))\n",
        "model.add(MaxPooling2D(strides=2))\n",
        "\n",
        "# model.add(Conv2D(30, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D(strides=2))\n",
        "\n",
        "model.add(Conv2D(12, (1, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(strides=2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.3))\n",
        "#model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "GwlXAe21liIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "optimizer=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0003),\n",
        "metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "t1Mc8FETdRwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "train_generator,\n",
        "epochs=5,\n",
        "validation_data=validation_generator) "
      ],
      "metadata": {
        "id": "rhOIXoNhd6UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "metadata": {
        "id": "roUDPadieTgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt \n",
        "# Save image in set directory\n",
        "# Read RGB image\n",
        "#path = \"/content/drive/MyDrive/faceData/test/true/WIN_20220513_00_40_18_Pro.jpg\"\n",
        "path = '/content/drive/MyDrive/faceData/test/false/WIN_20220513_00_40_45_Pro.jpg'\n",
        "_img = Image.open(path)\n",
        "_img.load()\n",
        "plt.imshow(_img)"
      ],
      "metadata": {
        "id": "NdM73YKEiJb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = tf.io.read_file(path)\n",
        "img = tf.image.decode_image(img)\n",
        "test_img = tf.image.resize(img, size = [img_height, img_height])\n",
        "test_img = test_img/255.\n",
        "val = model.predict(tf.expand_dims(test_img,axis=0))\n",
        "print(val)"
      ],
      "metadata": {
        "id": "F9wSBM8Fkf3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('myModel')"
      ],
      "metadata": {
        "id": "v2bSev6a9wxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/myModel') # path to the SavedModel directory\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('cao.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "nL6TANZq9_fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get -qq install xxd\n",
        "!xxd -i cao.tflite > waleed_FaceRecog_alt.cc"
      ],
      "metadata": {
        "id": "AeAa3E6qn3Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the signatures from the converted model\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "signatures = interpreter.get_signature_list()\n",
        "print(signatures)"
      ],
      "metadata": {
        "id": "mBMALtpc65xX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}